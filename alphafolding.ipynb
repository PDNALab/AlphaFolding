{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PDNALab/AlphaFolding/blob/main/alphafolding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapse": true
   },
   "source": [
    "### Iterative structure predictions with AlphaFold2 using only sequence\n",
    "- running iterative predictions with AlphaFold2 (monomer model 1,2) \n",
    "- visualization of structure predictions. \n",
    "- for predictions that succesfully find the native state, the structure predictions before native state can possibly resemble protein folding intermediates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapse": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "#@title setup {\"vertical-output\":true,\"form-width\":\"50%\",\"display-mode\":\"form\"}\n",
    "%%time\n",
    "import os\n",
    "if not os.path.isdir(\"params\"):\n",
    "  # get code\n",
    "  os.system(\"pip -q install git+https://github.com/ccccclw/ColabDesign.git\")\n",
    "  # for debugging\n",
    "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabdesign colabdesign\")\n",
    "  # download params\n",
    "  os.system(\"mkdir params\")\n",
    "  os.system(\"apt-get install aria2 -qq\")\n",
    "  os.system(\"aria2c -q -x 16 https://storage.googleapis.com/alphafold/alphafold_params_2022-12-06.tar\")\n",
    "  os.system(\"tar -xf alphafold_params_2022-12-06.tar -C params\")\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from Bio.PDB import *\n",
    "import os, re\n",
    "from colabdesign import mk_afdesign_model, clear_mem\n",
    "from colabdesign.mpnn import mk_mpnn_model\n",
    "from colabdesign.af.alphafold.common import residue_constants\n",
    "from colabdesign.shared.protein import _np_get_cb\n",
    "from colabdesign.shared.plot import plot_pseudo_3D, make_animation, show_pdb\n",
    "import pickle\n",
    "import json\n",
    "from colabdesign import af\n",
    "from google.colab import files\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from scipy.special import softmax\n",
    "import sys\n",
    "import tqdm.notebook\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import shutil\n",
    "import zipfile\n",
    "import os\n",
    "import threading\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'colab'\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "!pip install mdtraj\n",
    "import glob\n",
    "import mdtraj as md\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "TQDM_BAR_FORMAT = '{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]'\n",
    "\n",
    "##util functions\n",
    "def get_pdb(pdb_code=\"\"):\n",
    "  if pdb_code is None or pdb_code == \"\":\n",
    "    upload_dict = files.upload()\n",
    "    pdb_string = upload_dict[list(upload_dict.keys())[0]]\n",
    "    with open(\"tmp.pdb\",\"wb\") as out: out.write(pdb_string)\n",
    "    return \"tmp.pdb\"\n",
    "  elif os.path.isfile(pdb_code):\n",
    "    return pdb_code\n",
    "  elif len(pdb_code) == 4:\n",
    "    os.system(f\"wget -qnc https://files.rcsb.org/view/{pdb_code}.pdb\")\n",
    "    return f\"{pdb_code}.pdb\"\n",
    "  else:\n",
    "    os.system(f\"wget -qnc https://alphafold.ebi.ac.uk/files/AF-{pdb_code}-F1-model_v3.pdb\")\n",
    "    return f\"AF-{pdb_code}-F1-model_v3.pdb\"\n",
    "\n",
    "\n",
    "def get_dgram(positions, num_bins=39, min_bin=3.25, max_bin=50.75):\n",
    "  atom_idx = residue_constants.atom_order\n",
    "  atoms = {k:positions[...,atom_idx[k],:] for k in [\"N\",\"CA\",\"C\"]}\n",
    "  cb = _np_get_cb(**atoms, use_jax=False)\n",
    "  dist2 = np.square(cb[None,:] - cb[:,None]).sum(-1,keepdims=True)\n",
    "  lower_breaks = np.linspace(min_bin, max_bin, num_bins)\n",
    "  lower_breaks = np.square(lower_breaks)\n",
    "  upper_breaks = np.concatenate([lower_breaks[1:],np.array([1e8], dtype=jnp.float32)], axis=-1)\n",
    "  return ((dist2 > lower_breaks) * (dist2 < upper_breaks)).astype(float)\n",
    "\n",
    "def sample_gumbel(shape, eps=1e-10):\n",
    "  \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "  U = np.random.uniform(size=shape)\n",
    "  return -np.log(-np.log(U + eps) + eps)\n",
    "\n",
    "def sample_uniform(shape, eps=1e-10):\n",
    "  \"\"\"Sample from Uniform(0, 1)\"\"\"\n",
    "  U = np.random.uniform(size=shape)\n",
    "  return U + eps\n",
    "\n",
    "from colabdesign.af.alphafold.common import residue_constants\n",
    "def xyz_atom37(pdb_file):\n",
    "  \"\"\"\n",
    "  Convert atom coordinates [num_atom, 3] from xyz read from file such as pdb to atom37 format.\n",
    "  \"\"\"\n",
    "  atom37_order = residue_constants.atom_order\n",
    "  parser = PDBParser()\n",
    "  structure = parser.get_structure(\"A\", pdb_file)\n",
    "  atoms = list(structure.get_atoms())\n",
    "  length = len(list(structure.get_residues()))\n",
    "  atom37_coord = np.zeros((length, 37, 3))\n",
    "\n",
    "  for atom in atoms:\n",
    "    atom37_index = atom37_order[atom.get_name()]\n",
    "    residue_index = atom.get_parent().id[1]\n",
    "    atom37_coord[residue_index-1][atom37_index] = atom.get_coord()\n",
    "  return atom37_coord\n",
    "\n",
    "def sequence_to_one_hot(sequence):\n",
    "    \"\"\"\n",
    "    Convert a sequence string into a one-hot encoding matrix of shape (N, 20),\n",
    "    where N is the number of residues, and 20 is the number of amino acids.\n",
    "\n",
    "    Parameters:\n",
    "    - sequence: str, the input sequence of amino acids (e.g., \"ACDE\").\n",
    "\n",
    "    Returns:\n",
    "    - one_hot_matrix: np.ndarray, one-hot encoding matrix of shape (N, 20).\n",
    "    \"\"\"\n",
    "    # Convert the sequence to a list of integers using aa_order dictionary\n",
    "    aa_dict = residue_constants.restype_order\n",
    "    seq_indices = [aa_dict.get(aa, -1) for aa in sequence]  # -1 for unknown AA\n",
    "\n",
    "    # Ensure no unknown amino acids (-1) are present in the sequence\n",
    "    if any(idx == -1 for idx in seq_indices):\n",
    "        raise ValueError(\"Sequence contains invalid amino acid(s) not present in aa_order.\")\n",
    "\n",
    "    # Create a one-hot encoding matrix\n",
    "    N = len(sequence)\n",
    "    one_hot_matrix = np.eye(20)[seq_indices]\n",
    "\n",
    "    return one_hot_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapse": true
   },
   "outputs": [],
   "source": [
    "#@title input preparation {\"vertical-output\":true,\"form-width\":\"50%\",\"display-mode\":\"form\"}\n",
    "starting_seq = \"MTYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\" #@param {type:\"string\"}\n",
    "starting_seq = re.sub(\"[^A-Z]\", \"\", starting_seq.upper())\n",
    "##default sequence is PDB:3GB1 if no sequence is provided\n",
    "starting_seq = \"MTYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\" if len(starting_seq) == 0 else starting_seq\n",
    "length = len(starting_seq)\n",
    "template = \"None\" #@param [\"custom\",\"None\"]\n",
    "if template == \"custom\":\n",
    "  custom_template_path = os.path.join(template,f\"template\")\n",
    "  os.makedirs(custom_template_path, exist_ok=True)\n",
    "  uploaded = files.upload()\n",
    "  for fn in uploaded.keys():\n",
    "    os.rename(fn,os.path.join(custom_template_path,fn))\n",
    "  template_path = os.path.join(custom_template_path,fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapse": true
   },
   "outputs": [],
   "source": [
    "#@title initialize the model with parameters and run {\"vertical-output\":true,\"form-width\":\"50%\",\"display-mode\":\"form\"}\n",
    "clear_mem()\n",
    "model_name = \"model_1_ptm\" #@param [\"model_1_ptm\", \"model_2_ptm\",\"both\"]\n",
    "use_multimer = False \n",
    "model_name = None if model_name == \"both\" else [model_name]\n",
    "af_model = mk_afdesign_model(protocol=\"hallucination\",\n",
    "                             use_templates=True,\n",
    "                             debug=True, \n",
    "                             model_names=model_name,\n",
    "                             use_multimer=use_multimer)\n",
    "af_model.prep_inputs(length=length)\n",
    "\n",
    "mode = \"dgram\" #@param [\"dgram\",\"dgram_retrain\"]\n",
    "if \"dgram\" in mode:\n",
    "  if \"retrain\" in mode and not use_multimer:\n",
    "    # update distogram head to return all 39 bins\n",
    "    af_model._cfg.model.heads.distogram.first_break = 3.25\n",
    "    af_model._cfg.model.heads.distogram.last_break = 50.75\n",
    "    af_model._cfg.model.heads.distogram.num_bins = 39\n",
    "    af_model._model = af_model._get_model(af_model._cfg)\n",
    "    from colabdesign.af.weights import __file__ as af_path\n",
    "    template_dgram_head = np.load(os.path.join(os.path.dirname(af_path),'template_dgram_head.npy'))\n",
    "    for k in range(len(af_model._model_params)):\n",
    "      params = {\"weights\":jnp.array(template_dgram_head[k]),\"bias\":jnp.zeros(39)}\n",
    "      af_model._model_params[k][\"alphafold/alphafold_iteration/distogram_head/half_logits\"] = params\n",
    "  else:\n",
    "    dgram_map = np.eye(39)[np.repeat(np.append(0,np.arange(15)),4)]\n",
    "    dgram_map[-1,:] = 0 \n",
    "\n",
    "iterations = 50 #@param [50, 100, 200] {type:\"raw\"}\n",
    "use_dgram_noise = None #@param [\"g\",\"u\",\"None\"]\n",
    "use_dropout = False #@param {type:\"boolean\"}\n",
    "seqsep_mask =  0 #@param {type:\"integer\"}\n",
    "num_recycles = 2 #@param {type:\"integer\"}\n",
    "\n",
    "sample_models = True if model_name == \"both\" else False\n",
    "dgram_noise_type = use_dgram_noise\n",
    "use_dgram_noise = False if use_dgram_noise is None else True\n",
    "\n",
    "L = sum(af_model._lengths)\n",
    "af_model.restart(mode=\"gumbel\")\n",
    "af_model._inputs[\"rm_template_seq\"] = False\n",
    "# gather info about inputs\n",
    "if \"offset\" in af_model._inputs:           \n",
    "  offset = af_model._inputs\n",
    "else:\n",
    "  idx = af_model._inputs[\"residue_index\"]\n",
    "  offset = idx[:,None] - idx[None,:]\n",
    "\n",
    "# initialize sequence\n",
    "if len(starting_seq) > 1:\n",
    "  af_model.set_seq(seq=starting_seq)\n",
    "af_model._inputs[\"bias\"] = np.zeros((L,20))\n",
    "\n",
    "# initialize coordinates/dgram\n",
    "af_model._inputs[\"batch\"] = {\"aatype\":np.zeros(L).astype(int),\n",
    "                             \"all_atom_mask\":np.zeros((L,37)),\n",
    "                             \"all_atom_positions\":np.zeros((L,37,3)),\n",
    "                             \"dgram\":np.zeros((L,L,39))}\n",
    "\n",
    "if template == \"custom\":\n",
    "  xyz = xyz_atom37(pdb_file=template_path)\n",
    "  af_model._inputs[\"batch\"][\"all_atom_positions\"] = xyz\n",
    "  dgram = get_dgram(xyz)\n",
    "  mask = np.abs(offset) > seqsep_mask\n",
    "  af_model._inputs[\"batch\"][\"dgram\"] = dgram * mask[:,:,None]\n",
    "  if use_dgram_noise:\n",
    "    if dgram_noise_type == \"g\":   \n",
    "      noise = sample_gumbel(dgram.shape) * (1 - k/iterations)\n",
    "      dgram = softmax(np.log(dgram + 1e-8) + noise, -1)\n",
    "    elif dgram_noise_type == 'u':  \n",
    "      noise = sample_uniform(dgram.shape) * (1 - k/iterations)\n",
    "      dgram = softmax(np.log(dgram + 1e-8) + noise, -1)\n",
    "plddts = []\n",
    "print(f\"running seq {starting_seq} with model: {'both' if model_name is None else model_name} for {iterations} steps\")\n",
    "for k in range(iterations):\n",
    "  # noise\n",
    "  if k > 0:\n",
    "    dgram_xyz = get_dgram(xyz)\n",
    "    dgram_prob = softmax(dgram_logits,-1)\n",
    "\n",
    "    if mode == \"xyz\":\n",
    "      dgram = dgram_xyz\n",
    "    if mode == \"dgram\":\n",
    "      dgram = dgram_prob @ dgram_map\n",
    "      dgram[...,14:] = dgram_xyz[...,14:] * dgram_prob[...,-1:]\n",
    "    if mode == \"dgram_retrain\":\n",
    "      dgram = dgram_prob\n",
    "    \n",
    "    if use_dgram_noise:\n",
    "      if dgram_noise_type == \"g\":   \n",
    "        noise = sample_gumbel(dgram.shape) * (1 - k/iterations)\n",
    "        dgram = softmax(np.log(dgram + 1e-8) + noise, -1)\n",
    "      elif dgram_noise_type == 'u':  \n",
    "        noise = sample_uniform(dgram.shape) * (1 - k/iterations)\n",
    "        dgram = softmax(np.log(dgram + 1e-8) + noise, -1)\n",
    "\n",
    "    # add mask to avoid local contacts being fixed (otherwise there is a bias toward helix)\n",
    "    mask = np.abs(offset) > seqsep_mask\n",
    "    af_model._inputs[\"batch\"][\"dgram\"] = dgram * mask[:,:,None]\n",
    "\n",
    "  # prediction\n",
    "  aux = af_model.predict(return_aux=True, verbose=False,\n",
    "                        sample_models=sample_models,\n",
    "                        dropout=use_dropout, num_recycles=num_recycles)\n",
    "  plddt = aux[\"plddt\"]\n",
    "  plddts.append(np.average(plddt))\n",
    "  seq = aux[\"seq\"][\"hard\"][0].argmax(-1)   \n",
    "  xyz = aux[\"atom_positions\"].copy()\n",
    "  dgram_logits = aux[\"debug\"][\"outputs\"][\"distogram\"][\"logits\"] \n",
    "  \n",
    "  # update inputs    \n",
    "  af_model._inputs[\"batch\"][\"aatype\"] = seq\n",
    "  af_model._inputs[\"batch\"][\"all_atom_mask\"][:,:4] = np.sqrt(plddt)[:,None]\n",
    "  af_model._inputs[\"batch\"][\"all_atom_positions\"] = xyz\n",
    "  \n",
    "  # save results\n",
    "  af_model._save_results(aux)\n",
    "  af_model._k += 1\n",
    "  af_model.save_pdb(f\"iter_{k}.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapse": true
   },
   "outputs": [],
   "source": [
    "#@title visualization {\"vertical-output\":true,\"form-width\":\"50%\",\"display-mode\":\"form\"}\n",
    "fig,ax=plt.subplots(1,1,figsize=(7.4,2))\n",
    "ax.scatter(range(len(plddts)),np.array(plddts)*100,s=12, color='grey', zorder=1)\n",
    "ax.plot(np.array(plddts)*100,'darkorange',zorder=0)\n",
    "ax.set_xlabel(\"Prediction iteration\")\n",
    "ax.set_ylabel(\"pLDDT\")\n",
    "ax.text(ax.get_xlim()[0]+(ax.get_xlim()[1]-ax.get_xlim()[0])*0.85,\\\n",
    "        ax.get_ylim()[0]+(ax.get_ylim()[1]-ax.get_ylim()[0])*0.05,f\"recycle# {num_recycles}\")\n",
    "HTML(af_model.animate(dpi=80, interval=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapse": true
   },
   "outputs": [],
   "source": [
    "#@title Visualize precalculated iterative structure predictions from PDB {\"vertical-output\":true,\"form-width\":\"50%\",\"display-mode\":\"form\"}\n",
    "!pip install plotly\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "#import nglview as nv\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapse": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapse": true
   },
   "outputs": [],
   "source": [
    "#@title visualize embeddings {\"vertical-output\":true,\"form-width\":\"50%\",\"display-mode\":\"form\"}\n",
    "visualize_embeddings = True #@param {type:\"boolean\"}\n",
    "seq_length_min = 0 #@param {type:\"integer\"}\n",
    "seq_length_max = 100 #@param {type:\"integer\"}\n",
    "best_rmsd_min = 0 #@param {type:\"integer\"}\n",
    "best_rmsd_max = 3 #@param {type:\"integer\"}\n",
    "\n",
    "if visualize_embeddings:\n",
    "    if 'all_ss_gap0.npy' not in os.listdir('zenodo_downloads'):\n",
    "        download_file = ['all_ss_gap0.npy','all_ss_gap6.npy', \n",
    "                         'all_pdbs_gap0.npy','all_seq_length_gap0.npy',\n",
    "                         'all_rmsd_model1_gap0.npy','all_rmsd_model2_gap0.npy']\n",
    "        record_id = record_ids['18_and_embeddings']\n",
    "        download_zenodo(record_id=record_id,download_file=download_file)\n",
    "\n",
    "all_ss = np.load(\"./zenodo_downloads/all_ss_gap0.npy\")\n",
    "all_rmsd = np.load(\"./zenodo_downloads/all_rmsd_model1_gap0.npy\")\n",
    "all_rmsd2 = np.load(\"./zenodo_downloads/all_rmsd_model2_gap0.npy\")\n",
    "all_seq_length = np.load(\"./zenodo_downloads/all_seq_length_gap0.npy\")\n",
    "all_rmsd = np.array(all_rmsd)\n",
    "all_rmsd2 = np.array(all_rmsd2)\n",
    "all_tmfile_pd=np.load(\"./zenodo_downloads/all_pdbs_gap0.npy\")\n",
    "all_EH = np.array([[(np.array([*i])=='E').sum()/((np.array([*i])=='E').sum()+(np.array([*i])=='H').sum()),\n",
    "                    (np.array([*i])=='H').sum()/((np.array([*i])=='E').sum()+(np.array([*i])=='H').sum()),\n",
    "                    (np.array([*i])=='E').sum()/len(i),\n",
    "                    (np.array([*i])=='H').sum()/len(i),\n",
    "                    (np.array([*(i.strip('C'))])=='C').sum()/len(i)] for i in all_ss])\n",
    "all_H = [(np.array([*i])=='H').sum()/((np.array([*i])=='E').sum()+(np.array([*i])=='H').sum()) for i in all_ss]\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'colab'\n",
    "# import plotly.offline as pyo\n",
    "# pyo.init_notebook_mode(connected=True)\n",
    "long_seq_index = np.where((all_seq_length>seq_length_min) & (all_seq_length<seq_length_max))[0]\n",
    "all_X_embedded = np.load('./zenodo_downloads/rmsds_plddts_embeddings/TSE_embedding_gap0.npy')\n",
    "X_embedded = all_X_embedded[9]\n",
    "plot_embedding(X_embedded[long_seq_index],all_EH[long_seq_index],all_rmsd2[long_seq_index],np.array(all_tmfile_pd)[long_seq_index],selection='RMSD',selection_min=best_rmsd_min,selection_max=best_rmsd_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapse": true
   },
   "outputs": [],
   "source": [
    "#@title visualize individual pdb {\"vertical-output\":true,\"form-width\":\"50%\",\"display-mode\":\"form\"}\n",
    "pdb_id = \"3gb1\" #@param {type:\"string\"}\n",
    "pdb_id = pdb_id.lower()\n",
    "sub_traj_record_ids = {'zenodo_id_subtrajs.json':'13857269'}\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "!pip install mdtraj\n",
    "import glob\n",
    "import mdtraj as md\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Function to extract pLDDT values from a PDB file\n",
    "def get_plddt(pdb):\n",
    "    n_res = md.load(pdb).n_residues\n",
    "    run_residues = list(range(1, n_res+1))\n",
    "\n",
    "    with open(pdb, 'r') as fh:\n",
    "        atom_lines = []\n",
    "        for line in fh.readlines():\n",
    "            # atom_count = 0\n",
    "            if re.search(r'^ATOM', line):\n",
    "              # atom_lines.append(line)\n",
    "              # atom_count += 1\n",
    "                if int(line[22:26]) in run_residues:\n",
    "                    # atom_count += 1\n",
    "                    atom_lines.append(line)\n",
    "                    run_residues = run_residues[1:]\n",
    "        str_bfactors1 = [l[61:65] for l in atom_lines]\n",
    "        flt_bfactors1 = np.array([float(i)/100 for i in str_bfactors1]).astype(\"float32\")\n",
    "\n",
    "    return flt_bfactors1\n",
    "\n",
    "# Function to run get_plddt concurrently for multiple PDB files\n",
    "def process_plddts_in_parallel(pdb_files, max_workers=4):\n",
    "    plddts = {}\n",
    "\n",
    "    # Use ThreadPoolExecutor for multi-threading\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit tasks to the executor\n",
    "        futures = {executor.submit(get_plddt, pdb): pdb for pdb in pdb_files}\n",
    "\n",
    "        # Collect the results as they are completed\n",
    "        for future in as_completed(futures):\n",
    "            pdb = futures[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                plddts[pdb] = result\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {pdb}: {e}\")\n",
    "    return plddts\n",
    "\n",
    "if pdb_id is not None:\n",
    "    if pdb_id in fig_1_6_pdbs:\n",
    "        download_file = f\"{pdb_id.lower()}.zip\"\n",
    "        record_id = record_ids['18_and_embeddings']\n",
    "        download_zenodo(record_id,download_file=download_file)\n",
    "        download_file = os.path.join('zenodo_downloads', download_file)\n",
    "        extract_zip_multithreaded(download_file, 'zenodo_downloads', num_threads=4)\n",
    "    else:\n",
    "        download_zenodo('13857269',download_file='zenodo_id_subtrajs.json')\n",
    "        sub_traj_zenodo_id_index = json.load(open('zenodo_downloads/zenodo_id_subtrajs.json'))\n",
    "        sub_traj_zenodo_id_index_zip = {'1':['13841237','13836304'],'2':['13836288','13836290'],\n",
    "                                        '3':['13836306','13836308'],'4':['13836319','13836313'],\n",
    "                                        '5':['13836321'],'6':['13836295'],'7':['13841213'],'8':['13836304']}\n",
    "        sub_traj_zenodo_id = sub_traj_zenodo_id_index_zip[pdb_id[0]]\n",
    "        download_sub_traj_zenodo_id = []\n",
    "        for id in sub_traj_zenodo_id:\n",
    "            sub_traj_zips = sub_traj_zenodo_id_index[id].keys()\n",
    "            for zip_key in sub_traj_zips:\n",
    "                sub_trajs = sub_traj_zenodo_id_index[id][zip_key]\n",
    "                for sub_traj in sub_trajs:\n",
    "                    if sub_traj[-4:] == '.xtc' and pdb_id in sub_traj:\n",
    "                        download_sub_traj_zenodo_id.append((id, zip_key, sub_traj))\n",
    "        for (id, zip_key, sub_traj) in download_sub_traj_zenodo_id:\n",
    "            if not os.path.exists(os.path.join('zenodo_downloads', sub_traj)):\n",
    "              download_zenodo(id, download_file=zip_key)\n",
    "              # sub_traj = os.path.join('zenodo_downloads', sub_traj)\n",
    "            zip_key = os.path.join('zenodo_downloads', zip_key)\n",
    "            extract_zip_multithreaded(zip_key, 'zenodo_downloads', file_name=[pdb_id], num_threads=4)\n",
    "        extract_zip_multithreaded('zenodo_downloads/model_1_2_gap_0_6_per_residue_plddts.zip', 'zenodo_downloads', file_name=[pdb_id], num_threads=4)\n",
    "        extract_zip_multithreaded('zenodo_downloads/0_0_iter_0_pdb.zip', 'zenodo_downloads', file_name=[pdb_id], num_threads=4)\n",
    "\n",
    "\n",
    "# fig_1_6_trajs = {'3gb1':'run_2nd_nosamplemodel_model_1_gap0/2_0/','1mi0':'run_2nd_nosamplemodel_model_1_gap0/1_0/',\n",
    "#                  '1hz5':'run_2nd_nosamplemodel_model_1_gap0/0_0/','1kh0':'run_2nd_nosamplemodel_model_2_gap0/0_0/',\n",
    "#                  '1ubq':'run_2nd_nosamplemodel_model_1_gap0/2_0/','2hda':'run_2nd_nosamplemodel_model_1_gap0/2_0/',\n",
    "#                  '1fnf':'run_2nd_nosamplemodel_model_2_gap0/1_0/'}\n",
    "fig_1_6_trajs = {'3gb1':'run_2nd_nosamplemodel_model_1_gap0','1mi0':'run_2nd_nosamplemodel_model_1_gap0',\n",
    "                 '1hz5':'run_2nd_nosamplemodel_model_1_gap0','1kh0':'run_2nd_nosamplemodel_model_2_gap0',\n",
    "                 '1ubq':'run_2nd_nosamplemodel_model_1_gap0','2hda':'run_2nd_nosamplemodel_model_1_gap0',\n",
    "                 '1fnf':'run_2nd_nosamplemodel_model_2_gap0'}\n",
    "\n",
    "models = ['run_2nd_nosamplemodel_model_1_gap0','run_2nd_nosamplemodel_model_1_gap6','run_2nd_nosamplemodel_model_2_gap0','run_2nd_nosamplemodel_model_2_gap0']\n",
    "if pdb_id in fig_1_6_pdbs:\n",
    "  pdbs = [f\"zenodo_downloads/{pdb_id}/{fig_1_6_trajs[pdb_id]}/{recycle}_0/iter_{step}.pdb\" for recycle in range(11) for step in range(50)]\n",
    "  plddts = process_plddts_in_parallel(pdbs)\n",
    "  plddts = [plddts[pdb] for pdb in pdbs]\n",
    "  traj = md.load(pdbs)\n",
    "else:\n",
    "  traj = [glob.glob(f\"zenodo_downloads/*/{pdb_id}/{model}/*xtc\")[0] for model in models]\n",
    "\n",
    "  top = glob.glob(f\"zenodo_downloads/*/{pdb_id}/{pdb_id}*pdb\")[0]\n",
    "  total_frames = 2500\n",
    "  all_frames = list(range(total_frames))\n",
    "  traj_list = [x for i in range(0, total_frames, 500) for x in all_frames[i:i+100]]\n",
    "  traj_all = md.load(traj[0],top=top)[traj_list]\n",
    "  for i in range(1,4):\n",
    "    traj_all += md.load(traj[i],top=top)[traj_list]\n",
    "  plddts = []\n",
    "  for model in models:\n",
    "    plddts_json = glob.glob(f\"zenodo_downloads/*seq*/{pdb_id}/{model}/*plddt*json\")[0]\n",
    "    plddts_json = json.load(open(plddts_json))\n",
    "    plddts.append([plddts_json[f'{recycle}_0/iter_{step}.pdb'] for recycle in [0,1,3,5,8] for step in range(100)])\n",
    "  plddts = np.concatenate(plddts)/100\n",
    "CA_atoms=traj_all.top.select(f\"name CA\")\n",
    "traj_all=traj_all.atom_slice(CA_atoms)\n",
    "xyz = [traj_all.xyz[i]*10 for i in range(len(traj_all))]\n",
    "seq = [sequence_to_one_hot(traj_all.top.to_fasta()[0])[None,:,:]]*len(xyz)\n",
    "if pdb_id in fig_1_6_pdbs:\n",
    "  #recycling plot\n",
    "  first_max_hit = []\n",
    "  colors = plt.cm.plasma_r(np.linspace(0, 1, 12))[-11:]\n",
    "  fig,ax = plt.subplots(1,1,figsize=(10,2))\n",
    "  plot_steps = 20\n",
    "  plddts = np.array(plddts).reshape(11,50,len(plddts[-1]))\n",
    "  average_plddts = np.average(plddts, axis=2)\n",
    "  for i in range(11):\n",
    "    # file = f'/orange/alberto.perezant/liweichang/dev/colabdesign/example/known_folders/3gb1/model{i}_rseed0{j}/'\n",
    "    # print(f\"this is {file.split('/')[-3]+', '+file.split('/')[-2]} {j}th traj\")\n",
    "    tmp_max_hit = []\n",
    "    tmp_plddts = average_plddts[i]\n",
    "    ax.plot(tmp_plddts[:plot_steps]*100,label=str(i),color=colors[i])\n",
    "    ax.scatter(list(range(plot_steps)),tmp_plddts[:plot_steps]*100,s=20,color=colors[i])\n",
    "  ax.set_yticks(list(range(60,100,10)))\n",
    "  ax.set_xticks(list(range(0,plot_steps)))\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "else:\n",
    "  #plot plddts for four models\n",
    "  fig,ax=plt.subplots(4,1,figsize=(8.4,12))\n",
    "  average_plddts = plddts.mean(axis=1)\n",
    "\n",
    "  num_recycles = 5\n",
    "  recycles = [0,1,3,5,8]\n",
    "  cmap = cm.get_cmap('viridis', num_recycles) \n",
    "  norm = mcolors.Normalize(vmin=0, vmax=num_recycles-1)\n",
    "  models = ['model_1_gap_0','model_1_gap_6','model_2_gap_0','model_2_gap_6']\n",
    "  plot_steps = 50\n",
    "  # Plot the data using the colormap\n",
    "  for model in range(4):\n",
    "      for recycle in range(5):\n",
    "          color = cmap(recycle)  # Get the color from the colormap\n",
    "          start_step = model*500+recycle*100\n",
    "          tmp_plddts = average_plddts[start_step:start_step+plot_steps]*100\n",
    "          ax[model].plot(tmp_plddts,\n",
    "                        color=color,\n",
    "                        label=f'recycle {recycle}')\n",
    "          ax[model].scatter(list(range(len(tmp_plddts))),tmp_plddts,\n",
    "                        color=color,\n",
    "                        label=f'recycle {recycle}',s=15)\n",
    "\n",
    "      ax[model].set_xlabel(\"Prediction iteration\")\n",
    "      ax[model].set_ylabel(\"pLDDT\")\n",
    "      ax[model].set_title(f\"Model {models[model]}\",fontsize=9)\n",
    "  plt.tight_layout()\n",
    "  # Add a colorbar to indicate recycle steps\n",
    "  sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "  sm.set_array([])  # Needed to avoid a warning\n",
    "  cbar = fig.colorbar(sm, ax=ax,shrink=0.8, aspect=30) #, orientation='vertical', pad=0.02)\n",
    "  cbar.set_label('Recycle steps', rotation=270, labelpad=20)\n",
    "  cbar.set_ticks([0, 1, 2, 3, 4])\n",
    "  cbar.set_ticklabels(['0', '1', '3', '5', '8'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title structural visualization with selected model and recycle {\"vertical-output\":true,\"form-width\":\"50%\",\"display-mode\":\"form\"}\n",
    "model = 'model_1_gap_0' #@param ['model_1_gap_0','model_1_gap_6','model_2_gap_0','model_2_gap_6']\n",
    "recycle = \"0\" #@param ['0','1','3','5','8']\n",
    "\n",
    "models = ['model_1_gap_0','model_1_gap_6','model_2_gap_0','model_2_gap_6']\n",
    "recycles = ['0','1','3','5','8']\n",
    "models_index = models.index(model)\n",
    "recycle_index = recycles.index(recycle)\n",
    "start_index = models_index*500+recycle_index*100\n",
    "end_index = start_index+plot_steps\n",
    "sub_xyz = xyz[start_index:end_index]\n",
    "sub_plddts = plddts[start_index:end_index]\n",
    "sub_seq = seq[start_index:end_index]\n",
    "HTML(make_animation(sub_seq, xyz=sub_xyz, pae=None, plddt=sub_plddts, dpi=80, interval=300))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMekAuezg/uY2ZS27KOBLN+",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
